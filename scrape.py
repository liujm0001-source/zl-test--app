from duckduckgo_search import DDGS
import json
import time
import re

def scrape_via_search():
    # æ‰©å¤§èŒƒå›´ï¼šä¸å†é™åˆ¶ /news å­ç›®å½•ï¼Œæœå…¨ç«™
    keywords = "site:zhonglun.com (åŠ©åŠ› OR ä»£è¡¨ OR ä¸Šå¸‚ OR å¹¶è´­ OR è·é€‰)"
    
    print(f"--- æ­£åœ¨å…¨ç½‘æœç´¢: {keywords} ---")
    
    cases = []
    
    try:
        # === æ ¸å¿ƒä¿®æ”¹ï¼šå»æ‰äº† timelimit='m'ï¼Œä¸å†é™åˆ¶æ—¶é—´ ===
        results = DDGS().text(keywords, region='cn-zh', max_results=15)
        
        print(f"æœç´¢æœåŠ¡è¿”å›äº† {len(list(results)) if results else 0} æ¡ç»“æœ")

        for r in results:
            title = r.get('title', '')
            href = r.get('href', '')
            body = r.get('body', '') 
            
            # 1. è¿‡æ»¤ï¼šå¿…é¡»æ˜¯ä¸­ä¼¦å®˜ç½‘
            if "zhonglun.com" not in href: continue
            
            # 2. æ¸…æ´—æ ‡é¢˜
            title = title.split(' - ')[0].split(' | ')[0]
            
            # 3. æå–æ—¥æœŸ (å¦‚æœæœä¸åˆ°æ—¥æœŸï¼Œå°±ç»™ä¸ªé»˜è®¤çš„â€œè¿‘æœŸâ€)
            date = "è¿‘æœŸåŠ¨æ€"
            # å°è¯•åŒ¹é… 2023-2025 å¹´çš„æ—¥æœŸ
            date_match = re.search(r'(202[3-6][-./å¹´]\d{1,2}[-./æœˆ]\d{1,2})', body)
            if date_match:
                date = date_match.group(1).replace('.','-').replace('/','-').replace('å¹´','-').replace('æœˆ','-')
            
            # 4. å­˜å…¥
            if not any(c['link'] == href for c in cases):
                print(f"ğŸ” æŠ“å–: {title[:15]}...")
                cases.append({
                    "title": title,
                    "date": date,
                    "tag": "æœ€æ–°äº¤æ˜“",
                    "link": href
                })

    except Exception as e:
        print(f"âŒ æœç´¢å‡ºé”™: {e}")

    # æ’åºï¼šæŠŠå¸¦å…·ä½“æ—¥æœŸçš„æ’å‰é¢
    cases.sort(key=lambda x: x['date'] if x['date'][0].isdigit() else '0000', reverse=True)
    
    if len(cases) == 0:
        print("âš ï¸ ä¾ç„¶æœªæœåˆ°ï¼Œä½¿ç”¨ä¿åº•æ•°æ®")
        cases = [
            {
                "title": "ä¸­ä¼¦åŠ©åŠ›æµ·ä¼Ÿè‚¡ä»½åœ¨é¦™æ¸¯è”äº¤æ‰€ä¸»æ¿ä¸Šå¸‚", 
                "date": "2025-12-05", 
                "tag": "æœ€æ–°äº¤æ˜“", 
                "link": "https://www.zhonglun.com"
            }
        ]
    else:
        print(f"âœ… æˆåŠŸè·å– {len(cases)} æ¡æ•°æ®ï¼")

    with open('cases.json', 'w', encoding='utf-8') as f:
        json.dump(cases, f, ensure_ascii=False, indent=2)

if __name__ == "__main__":
    scrape_via_search()
