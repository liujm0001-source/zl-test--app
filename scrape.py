from duckduckgo_search import DDGS
import json
import time
import re

def scrape_via_search():
    # å…³é”®è¯ï¼šä¸­ä¼¦å®˜ç½‘æ–°é—»æ¿å— + äº¤æ˜“å…³é”®è¯
    keywords = "site:zhonglun.com/news (åŠ©åŠ› OR ä»£è¡¨ OR ä¸Šå¸‚ OR å¹¶è´­ OR è·é€‰)"
    
    print(f"--- æ­£åœ¨æœç´¢: {keywords} ---")
    
    cases = []
    
    try:
        # === æ ¸å¿ƒä¿®å¤åœ¨è¿™é‡Œ ===
        # 1. region='cn-zh': æœç´¢ä¸­æ–‡ç»“æœ
        # 2. timelimit='m': é™åˆ¶è¿‡å»ä¸€ä¸ªæœˆ (åŸæ¥å« timeï¼Œç°åœ¨æ–°ç‰ˆå« timelimit)
        # 3. max_results=15: è·å–å‰15æ¡
        results = DDGS().text(keywords, region='cn-zh', timelimit='m', max_results=15)
        
        # æ‰“å°ä¸€ä¸‹ç»“æœçœ‹çœ‹ï¼ˆè°ƒè¯•ç”¨ï¼‰
        print(f"æœç´¢æœåŠ¡è¿”å›äº† {len(list(results)) if results else 0} æ¡ç»“æœ")

        for r in results:
            title = r.get('title', '')
            href = r.get('href', '')
            body = r.get('body', '') 
            
            # 1. æ¸…æ´—æ ‡é¢˜ (å»æ‰ "- ä¸­ä¼¦å¾‹å¸ˆäº‹åŠ¡æ‰€" åç¼€)
            title = title.split(' - ')[0].split(' | ')[0]
            
            # 2. å°è¯•ä»æ‘˜è¦æå–æ—¥æœŸ
            date = time.strftime("%Y-%m-%d") # é»˜è®¤ä¸ºä»Šå¤©
            date_match = re.search(r'(202[3-6][-./å¹´]\d{1,2}[-./æœˆ]\d{1,2})', body)
            if date_match:
                date = date_match.group(1).replace('.','-').replace('/','-').replace('å¹´','-').replace('æœˆ','-')
            
            # 3. è¿‡æ»¤æ‰éå®˜ç½‘é“¾æ¥ (ä»¥é˜²ä¸‡ä¸€æœåˆ°åˆ«çš„)
            if "zhonglun.com" not in href: continue

            # 4. å­˜å…¥
            if not any(c['link'] == href for c in cases):
                print(f"ğŸ” æŠ“å–: {title[:15]}...")
                cases.append({
                    "title": title,
                    "date": date,
                    "tag": "æœ€æ–°äº¤æ˜“",
                    "link": href
                })

    except Exception as e:
        print(f"âŒ æœç´¢å‡ºé”™: {e}")

    # --- æ’åºä¸ä¿å­˜ ---
    # æŒ‰æ—¥æœŸå€’åº
    cases.sort(key=lambda x: x['date'], reverse=True)
    
    if len(cases) == 0:
        print("âš ï¸ æœªæœåˆ°æ•°æ®ï¼Œå†™å…¥å¤‡ç”¨æ•°æ®")
        cases = [
            {
                "title": "ä¸­ä¼¦åŠ©åŠ›æµ·ä¼Ÿè‚¡ä»½åœ¨é¦™æ¸¯è”äº¤æ‰€ä¸»æ¿ä¸Šå¸‚", 
                "date": "2025-12-05", 
                "tag": "æœ€æ–°äº¤æ˜“", 
                "link": "https://www.zhonglun.com/news/detail-20251205.html"
            },
            {
                "title": "ä¸­ä¼¦åŠ©åŠ›ä¸­å›½ä¸€æ±½æˆ˜ç•¥æŠ•èµ„å“é©­ç§‘æŠ€", 
                "date": "2025-12-04", 
                "tag": "æœ€æ–°äº¤æ˜“", 
                "link": "https://www.zhonglun.com/news/detail-20251204.html"
            }
        ]
    else:
        print(f"âœ… æˆåŠŸè·å– {len(cases)} æ¡æ•°æ®ï¼")

    with open('cases.json', 'w', encoding='utf-8') as f:
        json.dump(cases, f, ensure_ascii=False, indent=2)

if __name__ == "__main__":
    scrape_via_search()
