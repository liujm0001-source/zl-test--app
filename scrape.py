from duckduckgo_search import DDGS
import json
import time
import re

def scrape_via_search():
    # æœç´¢å…³é”®è¯ï¼šé™å®šåœ¨ä¸­ä¼¦æ–°é—»æ¿å—ï¼ŒåŒ…å«â€œåŠ©åŠ›â€æˆ–â€œä»£è¡¨â€çš„è¯
    # time='m' è¡¨ç¤ºåªæœâ€œè¿‡å»ä¸€ä¸ªæœˆâ€çš„ï¼Œç¡®ä¿æ–°é²œ
    keywords = "site:zhonglun.com/news (åŠ©åŠ› OR ä»£è¡¨ OR ä¸Šå¸‚ OR å¹¶è´­)"
    
    print(f"--- æ­£åœ¨é€šè¿‡æœç´¢å¼•æ“æŸ¥æ‰¾: {keywords} ---")
    
    cases = []
    
    try:
        # ä½¿ç”¨ DuckDuckGo æœç´¢
        # region='cn-zh' ä¼˜å…ˆæ‰¾ä¸­æ–‡ç»“æœ
        # time='m' é™åˆ¶è¿‡å»ä¸€ä¸ªæœˆ
        # max_results=15 æŠ“å–å‰15æ¡
        results = DDGS().text(keywords, region='cn-zh', time='m', max_results=15)
        
        for r in results:
            title = r.get('title', '')
            href = r.get('href', '')
            body = r.get('body', '') # æ‘˜è¦ï¼Œé‡Œé¢é€šå¸¸åŒ…å«æ—¥æœŸ
            
            # 1. ç®€å•æ¸…æ´—æ ‡é¢˜
            # æœç´¢ç»“æœæ ‡é¢˜é€šå¸¸å¸¦æœ‰ " - ä¸­ä¼¦å¾‹å¸ˆäº‹åŠ¡æ‰€"ï¼Œæˆ‘ä»¬è¦å»æ‰
            title = title.split(' - ')[0].split(' | ')[0]
            
            # 2. å°è¯•ä»æ‘˜è¦é‡Œæå–æ—¥æœŸï¼Œå¦‚æœæ²¡æœ‰å°±ç”¨ä»Šå¤©
            # æ‘˜è¦é‡Œé€šå¸¸ä¼šæœ‰ "2 days ago" æˆ–è€… "2023..."
            date = time.strftime("%Y-%m-%d")
            
            # å°è¯•åŒ¹é…æ—¥æœŸæ ¼å¼ YYYY-MM-DD
            date_match = re.search(r'(202[3-6][-./å¹´]\d{1,2}[-./æœˆ]\d{1,2})', body)
            if date_match:
                date = date_match.group(1).replace('.','-').replace('/','-').replace('å¹´','-').replace('æœˆ','-')
            
            # 3. å­˜å…¥ç»“æœ
            if not any(c['link'] == href for c in cases):
                print(f"ğŸ” æœåˆ°: {title[:15]}...")
                cases.append({
                    "title": title,
                    "date": date,
                    "tag": "æœ€æ–°äº¤æ˜“", # ç»Ÿä¸€æ‰“æ ‡
                    "link": href
                })

    except Exception as e:
        print(f"æœç´¢å‡ºé”™: {e}")

    # --- å…œåº•é€»è¾‘ ---
    # å¦‚æœæœä¸åˆ°ï¼ˆæå°‘æƒ…å†µï¼‰ï¼Œå†™å…¥ä¸€æ¡æç¤º
    if len(cases) == 0:
        print("âš ï¸ æœç´¢å¼•æ“æœªè¿”å›æ•°æ®")
        cases = [
            {
                "title": "ç‚¹å‡»æŸ¥çœ‹ä¸­ä¼¦å®˜ç½‘æœ€æ–°ä¸šç»© (è‡ªåŠ¨åŒæ­¥æš‚ç¼“)", 
                "date": time.strftime("%Y-%m-%d"), 
                "tag": "å¿«é€Ÿè®¿é—®", 
                "link": "https://www.zhonglun.com/news.html"
            }
        ]
    else:
        print(f"âœ… æˆåŠŸé€šè¿‡æœç´¢è·å– {len(cases)} æ¡æ•°æ®ï¼")

    # ä¿å­˜
    with open('cases.json', 'w', encoding='utf-8') as f:
        json.dump(cases, f, ensure_ascii=False, indent=2)

if __name__ == "__main__":
    scrape_via_search()
